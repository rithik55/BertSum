{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "historical-pontiac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /Users/priyank/miniconda3/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-cloud-storage) (2.25.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-cloud-storage) (2.15.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-cloud-storage) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (4.25.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/priyank/miniconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compact-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varying-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")  # Set the tracking URI to the Minikube service\n",
    "\n",
    "# Ensure Google Application Credentials are set for GCS\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"cs505.json\"\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intermediate-gnome",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyank/miniconda3/envs/dl-prac/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'demo_model' already exists. Creating a new version of this model...\n",
      "2023/12/23 13:45:56 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: demo_model, version 4\n",
      "Created version '4' of model 'demo_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poor Logistic Regression model accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Model 1: Poorly performing model\n",
    "# Using very strong regularization (C very small) to underfit\n",
    "C_poor = 0.001\n",
    "solver_poor = 'liblinear'\n",
    "\n",
    "with mlflow.start_run(run_name=\"Poor_Model\"):\n",
    "    clf_poor = LogisticRegression(C=C_poor, solver=solver_poor, random_state=42)\n",
    "    clf_poor.fit(X_train[:30], y_train[:30])  # Using only a small part of the training data\n",
    "\n",
    "    predictions_poor = clf_poor.predict(X_test)\n",
    "    accuracy_poor = accuracy_score(y_test, predictions_poor)\n",
    "\n",
    "    mlflow.log_param(\"C\", C_poor)\n",
    "    mlflow.log_param(\"solver\", solver_poor)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_poor)\n",
    "    mlflow.sklearn.log_model(clf_poor, \n",
    "                             artifact_path=\"logistic-regression-model-poor\", registered_model_name=\"demo_model\")\n",
    "\n",
    "    print(f\"Poor Logistic Regression model accuracy: {accuracy_poor:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interracial-darwin",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'demo_model' already exists. Creating a new version of this model...\n",
      "2023/12/23 13:46:02 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: demo_model, version 5\n",
      "Created version '5' of model 'demo_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Logistic Regression model accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Well-performing model\n",
    "# Using standard regularization and full training data\n",
    "C_good = 1.0\n",
    "solver_good = 'liblinear'\n",
    "\n",
    "with mlflow.start_run(run_name=\"Good_Model\"):\n",
    "    clf_good = LogisticRegression(C=C_good, solver=solver_good, random_state=42)\n",
    "    clf_good.fit(X_train, y_train)\n",
    "\n",
    "    predictions_good = clf_good.predict(X_test)\n",
    "    accuracy_good = accuracy_score(y_test, predictions_good)\n",
    "\n",
    "    mlflow.log_param(\"C\", C_good)\n",
    "    mlflow.log_param(\"solver\", solver_good)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_good)\n",
    "    mlflow.sklearn.log_model(clf_good, \n",
    "                             artifact_path=\"logistic-regression-model-good\", \n",
    "                             registered_model_name=\"demo_model\")\n",
    "\n",
    "    print(f\"Good Logistic Regression model accuracy: {accuracy_good:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "plain-pledge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'demo_model' already exists. Creating a new version of this model...\n",
      "2023/12/23 13:46:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: demo_model, version 6\n",
      "Created version '6' of model 'demo_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Logistic Regression model accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Well-performing model\n",
    "# Using standard regularization and full training data\n",
    "C_good = 1.0\n",
    "solver_good = 'liblinear'\n",
    "\n",
    "with mlflow.start_run(run_name=\"Good_Model\"):\n",
    "    clf_good = LogisticRegression(C=C_good, solver=solver_good, random_state=42)\n",
    "    clf_good.fit(X_train, y_train)\n",
    "\n",
    "    predictions_good = clf_good.predict(X_test)\n",
    "    accuracy_good = accuracy_score(y_test, predictions_good)\n",
    "\n",
    "    mlflow.log_param(\"C\", C_good)\n",
    "    mlflow.log_param(\"solver\", solver_good)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_good)\n",
    "    mlflow.sklearn.log_model(clf_good, \n",
    "                             artifact_path=\"logistic-regression-model-good\", \n",
    "                             registered_model_name=\"demo_model\")\n",
    "\n",
    "    print(f\"Good Logistic Regression model accuracy: {accuracy_good:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organizational-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT summarization model logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")  # Set the tracking URI to your MLflow server\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"cs505.json\"\n",
    "\n",
    "# BERT Summarization Model setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = EncoderDecoderModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Log BERT model to MLflow\n",
    "with mlflow.start_run(run_name=\"BERT_Summarization_Model\"):\n",
    "    # Log model details\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "\n",
    "    # Log the BERT model\n",
    "    # Note: You need a custom method to log the transformers model to MLflow\n",
    "    # This is a placeholder for model logging. The actual implementation will\n",
    "    # depend on how you intend to use and deploy the model.\n",
    "    # Example: mlflow.pytorch.log_model(model, \"bert_summarization_model\")\n",
    "    mlflow.log_param(\"max_length\", 512)  # Logging the max_length parameter\n",
    "\n",
    "    print(\"BERT summarization model logged to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT summarization model logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")  # Set the tracking URI to your MLflow server\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"cs505.json\"\n",
    "\n",
    "\n",
    "# BERT Summarization Model setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = EncoderDecoderModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Function to log hyperparameters during summarization\n",
    "def log_user_hyperparameters(temperature, top_k, top_p):\n",
    "    with mlflow.start_run(run_name=\"User Generated Summarization Parameters\"):\n",
    "        mlflow.log_param(\"temperature\", temperature)\n",
    "        mlflow.log_param(\"top_k\", top_k)\n",
    "        mlflow.log_param(\"top_p\", top_p)\n",
    "        print(f\"Logged user hyperparameters: temperature={temperature}, top_k={top_k}, top_p={top_p}\")\n",
    "\n",
    "         \n",
    "# Log BERT model to MLflow\n",
    "with mlflow.start_run(run_name=\"BERT_Summarization_Model\"):\n",
    "    # Log model details\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "    mlflow.log_param(\"max_length\", 512)  # Logging the max_length parameter\n",
    "\n",
    "    # Placeholder for model logging\n",
    "    # Example: mlflow.pytorch.log_model(model, \"bert_summarization_model\")\n",
    "    print(\"BERT summarization model logged to MLflow\")\n",
    "\n",
    "    \n",
    "# The function `log_user_hyperparameters` should be called from the Streamlit app \n",
    "# when generating a summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-neighbor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL Practice",
   "language": "python",
   "name": "dl-prac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
